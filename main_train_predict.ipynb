{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.preprocessor import preprocess_data, remap_class\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils.Dataset import CustomDataset\n",
    "\n",
    "from utils.eval import plot_confusion_matrix, plot_data_distribution\n",
    "from utils.helper import create_dir_not_exist, file_exist\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import Dataset\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline, AutoConfig, Trainer, TrainingArguments\n",
    "from commons.modeleval import f1metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "model_alternate_name = \"roberta2022\"\n",
    "\n",
    "resources_dir = \"resources\"\n",
    "    \n",
    "model_dir = f\"{resources_dir}/models\"\n",
    "model_bin_path = f\"{model_dir}/bin\"\n",
    "tokenizer_path = f\"{model_dir}/tokenizer\"\n",
    "\n",
    "other_dir = f\"{resources_dir}/other\" #for other constraints, instructions, blacklists, etc\n",
    "path_blacklist_sentence = f\"{other_dir}/blacklist_sentence.txt\"\n",
    "\n",
    "dataset_dir = f\"dataset\"\n",
    "input_data = f\"{dataset_dir}/input.csv\"\n",
    "output_cache = f\"{dataset_dir}/output.csv\"\n",
    "\n",
    "all_plot_data_distribution_path = f\"{output_cache}/eval/all_plot_data_distribution.png\"\n",
    "train_plot_data_distribution_path = f\"{output_cache}/eval/train_plot_data_distribution.png\"\n",
    "test_plot_data_distribution_path = f\"{output_cache}/eval/test_plot_data_distribution.png\"\n",
    "test_plot_confusion_matrix_path = f\"{output_cache}/eval/test_plot_confusion_matrix.png\"\n",
    "multi_Score_fscore_path = f\"{output_cache}/plot_multi_fscore.png\"\n",
    "\n",
    "text_column = \"text\"\n",
    "label_column = \"label\"\n",
    "\n",
    "label_mapping = {1: 0, 2: 1, 3: 2, 4: 3, 5: 4}\n",
    "vis_label = ['Label1', 'Label2', 'Label3', 'Label4', 'Label5']\n",
    "infer_mapping_firstlevel = {'LABEL_4': 5, 'LABEL_3': 4, 'LABEL_2': 3, 'LABEL_1': 2, 'LABEL_0': 1}\n",
    "infer_mapping_secondlevel = {5:'VERY POSITIVE', 4:'POSITIVE', 3:'NEUTRAL', 2:'NEGATIVE', 1:'VERY NEGATIVE'}\n",
    "\n",
    "seed = 42\n",
    "max_length = 256\n",
    "train_batch_size = 8\n",
    "val_batch_size = 8\n",
    "lr = 2e-5\n",
    "num_epochs = 5\n",
    "num_labels = 5\n",
    "weight_decay = 0.01\n",
    "\n",
    "configs = f\"\"\"\n",
    "preprocessing_steps = remove_blacklist_sentences, remove_url, filter_non_english_words, remove_square_bracket\n",
    "model_name = {model_name}\n",
    "manual_seed = {seed}\n",
    "max_length = {max_length}\n",
    "train_batch_size = {train_batch_size}\n",
    "val_batch_size = {val_batch_size}\n",
    "lr = {lr}\n",
    "num_epochs = {num_epochs}\n",
    "num_labels = {num_labels}\n",
    "weight_decay = {weight_decay}\n",
    "\"\"\"\n",
    "\n",
    "create_dir_not_exist(model_output)\n",
    "create_dir_not_exist(f\"{model_output}/eval\")\n",
    "create_dir_not_exist(pretrain_save_path)\n",
    "create_dir_not_exist(tokenizer_save_path)\n",
    "    \n",
    "with open(config_file, 'w') as file:\n",
    "    file.write(configs)\n",
    "    \n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main\n",
    "df = pd.read_csv(all_data)\n",
    "train_df = pd.read_csv(train_data_path)\n",
    "test_df = pd.read_csv(test_data_path)\n",
    "\n",
    "# plot_data_distribution(df, label_column, save_path=all_plot_data_distribution_path)\n",
    "# plot_data_distribution(train_df, label_column, save_path=train_plot_data_distribution_path)\n",
    "# plot_data_distribution(test_df, label_column, save_path=test_plot_data_distribution_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[text_column] = train_df[text_column].apply(preprocess_data)\n",
    "train_df = remap_class(train_df, label_column, label_mapping)\n",
    "\n",
    "test_df[text_column] = test_df[text_column].apply(preprocess_data)\n",
    "test_df = remap_class(test_df, label_column, label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    preds = predictions.argmax(axis=1)\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average='weighted')  # Using weighted average for F1\n",
    "    return {'accuracy': accuracy, 'f1': f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeigtedLossTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        labels = inputs.get(\"labels\")\n",
    "        loss_fn = nn.CrossEntropyLoss(weight=class_weights)\n",
    "        loss = loss_fn(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "config.num_labels = num_labels\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name, config=config, ignore_mismatched_sizes=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(), lr=lr, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = pd.concat([train_df, test_df], ignore_index=True)\n",
    "class_weights = (1-(train_df[label_column].value_counts().sort_index() / len(train_df))).values\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[text_column], truncation=True, padding='max_length', max_length=max_length)\n",
    "\n",
    "encoded_train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
    "encoded_test_dataset = test_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    num_train_epochs=num_epochs,\n",
    "    learning_rate=lr,\n",
    "    per_device_train_batch_size=train_batch_size,\n",
    "    per_device_eval_batch_size=val_batch_size,\n",
    "    weight_decay=weight_decay,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    output_dir=model_output,\n",
    "    logging_dir=f'{model_output}/logs',\n",
    "    logging_steps=10,\n",
    "    fp16=True\n",
    ")\n",
    "\n",
    "trainer = WeigtedLossTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=encoded_train_dataset,\n",
    "    eval_dataset=encoded_test_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Fine-tune the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(f\"Evaluation Results: {eval_results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(pretrain_save_path)\n",
    "tokenizer.save_pretrained(tokenizer_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_output = trainer.predict(encoded_test_dataset)\n",
    "predictions = predictions_output.predictions\n",
    "true_labels_list = predictions_output.label_ids\n",
    "\n",
    "predicted_labels_list = predictions.argmax(axis=1)\n",
    "\n",
    "f1metrics(true_labels_list, predicted_labels_list)\n",
    "\n",
    "# Save evals\n",
    "data = {\n",
    "        'true_labels': true_labels_list,\n",
    "        'predicted_labels': predicted_labels_list,\n",
    "        'text': test_df[text_column],\n",
    "        'difference': [abs(a - b) for a, b in zip(true_labels_list, predicted_labels_list)]\n",
    "    }\n",
    "labels_true_predicted_df = pd.DataFrame(data)\n",
    "labels_true_predicted_df.to_csv(f\"{model_output}/labels_true_predicted.csv\", index=False)\n",
    "plot_confusion_matrix(labels_true_predicted_df.true_labels, labels_true_predicted_df.predicted_labels,\n",
    "                        vis_label, save_path=test_plot_confusion_matrix_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(textlist):\n",
    "    tokenizer_kwargs = {'padding': True, 'truncation': True, 'max_length': max_length}\n",
    "\n",
    "    pipe = pipeline(\"text-classification\",\n",
    "                    model=model, tokenizer=tokenizer, device=device,\n",
    "                    **tokenizer_kwargs)\n",
    "    result = []\n",
    "    for text in tqdm(textlist):\n",
    "        rel = pipe(text)[0]\n",
    "        label = rel[\"label\"]\n",
    "        score = rel[\"score\"]\n",
    "        result.append({\"text\": text,\n",
    "                        \"label\": label,\n",
    "                        \"score\": score})\n",
    "    return result\n",
    "        \n",
    "new_df = pd.DataFrame({'text': \n",
    "    [\"\n",
    "     \"Commuting for me involves traveling between home and work, and I can choose between driving, taking public transportation, or biking\"\n",
    "     ]})\n",
    "\n",
    "new_df['text'] = new_df['text'].apply(preprocess_data)\n",
    "result = predict(new_df['text'].values)\n",
    "\n",
    "for res in result:\n",
    "    print(f\"\"\"\n",
    "    text: {res['text']}\n",
    "    label: {infer_mapping_secondlevel[infer_mapping_firstlevel[res['label']]]}\n",
    "    \"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
